• Trusted Authority (TA): The TA is assumed to be fully trusted and
operates honestly. It is responsible for initializing the system, generating cryptographic keys, enforcing access policies, and distributing the encrypted global model. The security of the system relies on the confidentiality and integrity of the TA’s operations.
• Fog Nodes: Fog nodes are considered honest but curious. They correctly
perform partial aggregation of model updates using FedAvg, but may
attempt to learn information from the updates. To mitigate this risk,
only secret shares and differentially private updates are handled by fog
nodes.
• Participants (Healthcare Facilities): Participants are assumed honestbut-curious. They train local models on sensitive patient data and generate secret shares of their updates. They may attempt to extract additional
information from the global model, but Shamir’s secret sharing and differential privacy ensure that individual data remains confidential.
• Validator Committee: Committee members are semi-trusted. They
verify secret shares, validate updates, and monitor malicious behavior.
They may attempt collusion, but rotating committees and role separation
reduce this risk.
• Leader Server: The leader server is randomly selected from fog nodes
for each global aggregation round. It is assumed to follow the protocol but
is still monitored through validation to mitigate potential misbehavior.
the TA and leader server are diffrent
2.4.1 System Initialization
In the initialization phase, the Trusted Authority (TA) creates the foundation
of the federated learning framework. The TA executes the setup procedure of
Ciphertext-Policy Attribute-Based Encryption (CP-ABE), generating a public
key (PK) and a master secret key (MSK). The public key is shared with all
participants, while the master secret key is kept strictly confidential by the TA.
At the same time, the TA defines the set of registered medical facilities U and
establishes the attribute universe A, which contains categorical descriptors such
as role, institution type, or region. These attributes later control which participants are allowed to access and decrypt the distributed models. The process
can be summarized by the following equation:
Setup(1k, U, A) → (PK, MSK)
where k is the system’s security parameter, U represents the set of facilities,
and A denotes the attribute universe. Once the setup is complete, the TA generates a private decryption key for each registered facility based on its attributes.
This guarantees that only facilities meeting specific attribute-based policies can
decrypt encrypted models in the later phases. To prevent malicious entities from
flooding the system with fake identities (Sybil attacks) or spamming registration
requests, every facility must solve a Proof-of-Work (PoW) challenge before registration. The PoW mechanism requires the facility to compute a valid nonce
that, when hashed with its identity and public key, produces a digest below
a predefined difficulty target. This ensures that the facility expends real computational resources to prove its legitimacy. The PoW condition is expressed as:
H(nonce ∥ F acility ID ∥ PK) ≤ T arget
Here, H represents a secure hash function, nonce is the random number adjusted by the facility, F acility ID is its unique identifier, and PK is the system’s
public key. The Target defines the difficulty level chosen by the TA. Facilities repeatedly adjust the nonce until the condition is satisfied. This procedure works
as follows:
• The TA issues a challenge by specifying the difficulty target.
• The facility repeatedly computes the hash of (nonce||F acility ID||PK).
• If the resulting hash is greater than the target, the facility changes the
nonce and retries.
• Once a valid nonce is found, the facility sends the solution to the TA.
• The TA verifies the hash in constant time, ensuring that the facility actually performed the computation.
9Through this mechanism, the system ensures that every registered participant
has a computational cost associated with its identity, making Sybil attacks impractical. Only after passing this challenge does the TA provide the facility with
its attribute-based secret key. The setup and PoW registration procedures can
be illustrated by Algorithm 1 and Algorithm 2, respectively.
Algorithm 1 System Setup by Trusted Authority (TA)
Input: Security parameter λ, set of facilities U, attribute universe A
Output: Public Key PK, Master Secret Key MSK
1: (PK, MSK) ← Setup(λ, U, A)
2: TA securely stores MSK and distributes PK to all registered facilities
3: Define attribute-based access policies for model decryption
Algorithm 2 Facility Registration with Proof-of-Work
Input: Facility request Req, difficulty parameter D
Output: Verified facility F and issued secret keys
1: Facility solves PoW challenge: Nonce ← FindNonce(H(Req||Nonce) < D)
2: if PoW verified by TA then
3: TA issues secret key SKfacility based on CP-ABE attributes
4: Register facility in system database
5: end if
2.4.2 Model Distribution
After initialization, the Trusted Authority (TA) prepares and distributes the
initial machine learning model across the federation in a secure and controlled
manner. The TA encrypts the global model using Ciphertext-Policy AttributeBased Encryption (CP-ABE), ensuring that only facilities whose attributes satisfy the access policy can decrypt and use the model. The encryption process
enforces fine-grained access control while preventing unauthorized entities from
gaining access, even if they intercept the ciphertext. The encryption algorithm
is expressed as:
Encrypt(Model, PK, T) → CT
where Model is the initial global model, PK is the public key from the setup
phase, and T is the access policy tree that encodes attribute-based restrictions
(e.g., facilitytype = hospital AND region = North). The output CT is the encrypted ciphertext of the model. When a registered facility wishes to obtain the
global model, it must first authenticate itself by sending an encrypted request
10to the Leader Server (randomly selected from among fog nodes). This ensures
secure communication between facilities and fog infrastructure. The encrypted
request is computed as:
Encrypt(PKLeader, req) → encryReq
where req is the facility’s request for the model and PKLeader is the public
key of the leader server. Upon receiving encryReq, the leader server decrypts
the request to recover req. Once verified, the leader server transmits the CPABE ciphertext CT to the requesting facility. Only facilities whose attributes
satisfy the policy T can decrypt the ciphertext. The decryption process is:
Decrypt(CT, SKuser)) → Model
where SKuser is the private decryption key generated by the TA for that
facility during initialization. This process ensures several guarantees:
• Confidentiality – Only facilities with valid attributes can decrypt and access the model.
• Controlled Distribution – Unauthorized entities, even if they intercept the
ciphertext, cannot recover the model.
• Scalability – Multiple facilities can request the model simultaneously from
the fog-based leader server without overloading the TA.
• Authentication – Facilities prove their legitimacy by encrypting their requests to the leader server, which prevents replay or impersonation attacks.
As a result, the model distribution stage establishes a secure channel between the
federation coordinator and the medical facilities, ensuring that only legitimate
and policy-compliant participants begin local training.
The secure distribution of the initial global model, including CP-ABE encryption and request authentication, is detailed in Algorithm 3.
Algorithm 3 Initial Model Distribution and Decryption by Facility
Input: Encrypted initial model CT, facility private key SKfacility
Output: Decrypted initial model Minit
1: Minit ← User Decrypt(CT, SKfacility)
2: Facility uses Minit as the starting point for local training
2.4.3 Local Training, Differential Privacy, and Secret Sharing
After receiving the encrypted global model from the leader server, each medical
facility decrypts it using its private key obtained during system initialization.
11The decryption is performed as:
User Decrypt(CT, SKfacility) → Model
where CT is the encrypted global model and SKfacility is the facility’s private secret key. If the facility’s attributes satisfy the CP-ABE policy, the decryption succeeds. Once the global model is obtained, each facility performs
local training on its private dataset Di for a specified number of epochs E.

The current CP-ABE implementation is for DEMONSTRATION ONLY and does not provide real cryptographic security:

2.4.4 Validation and Committee Mechanism
After each facility generates shares of its differentially private local model, these
shares are sent to the validator committee for integrity verification and authentication before being broadcast to fog nodes. The validator committee ensures
Byzantine fault tolerance, Sybil resistance, and trust in the federation. Proofof-Work for Facility Validation Before any facility can submit its shares, it must
solve a computational puzzle to prevent spam and Sybil attacks. The Proof-ofWork (PoW) mechanism is defined as:
12Algorithm 4 Local Training with Differential Privacy
Input: Initial model Minit, local dataset d, learning rate η, number of epochs
E, noise scale σ
Output: Differentially private local model MDP
local
1: for epoch = 1 to E do
2: Compute gradient: ∇Fi(Minit) using local dataset d
3: Add DP noise: ∇ ← ∇ ˜ Fi(Minit) + N (0, σ2)
4: Update model: MDP
local ← Minit − η∇˜
5: end for
Algorithm 5 Secret Sharing and Broadcast to Validator Committee
Input: Local model MDP
local, number of fog nodes n
Output: Secret shares S1, S2, ..., Sn
1: Divide MDP
local into n shares using Shamir’s Secret Sharing
2: for each share Si do
3: Send Si to validator committee for verification
4: end for
5: Broadcast approved shares to fog nodes
H(N ∥ IDfacility) < T
where:
• H is a cryptographic hash function,
• N is a nonce,
• IDfacility is the facility’s identity,
• T is the system-defined difficulty threshold.
Only if the hash output is below the target T, the facility’s request is accepted
by the committee. This ensures that each facility invests computational effort
before being able to contribute.
Digital Signature Authentication
Each facility signs its shares before sending them to the validator committee:
Sign(SKfacility, sij) → Sigi
where SKfacility is the facility’s signing key. The committee verifies:
13V erify(PKfacility, sij, Sigi) = True
If the verification fails, the share is discarded. This guarantees authenticity
and prevents tampering.
Committee Consensus Voting
Once authenticated, the committee validates whether the share is consistent
and well-formed. Each committee member Ck casts a binary vote (1 = valid, 0
= invalid). The final decision is determined by majority consensus:
Decision(sij) = (1, if Pm k=1 V otek(sij) ≥ m2 + 1
0, otherwise
where m is the number of committee members.
Only if the majority votes “valid,” the share is approved.
Secure Broadcast
Approved shares are then broadcast to their respective fog nodes:
Broadcast(Committee, sij) → F ogNodej
Each broadcast message is signed by the committee to ensure end-to-end
integrity:
Sign(SKCommittee, sij) → SigCommittee
The fog node accepts a share only if:
V erify(PKCommittee, sij, SigCommittee) = True
This ensures that fog nodes receive only verified and committee-approved
contributions.
The validator committee’s verification, consensus voting, and secure broadcast of approved shares are captured in Algorithm 6.
2.4.5 Fog Node Aggregation
After validation, the fog nodes assume the role of regional aggregators.
Security and Authentication
Before sending, fog nodes attach digital signatures to their partial models.
This prevents tampering during transmission and ensures integrity. The leader
server verifies each signature before proceeding with global aggregation:
V erify(Signfogj(Mfogj)) = T rue ∀j ∈ {1, . . . , n}
Only authenticated and validated partial models are accepted.
The partial aggregation by fog nodes, including collection, FedAvg computation, signing, and forwarding to the leader server, is described in Algorithm 7.
Algorithm 7 Fog Node Partial Aggregation
Input: Verified shares S1..n from facilities in the fog region
Output: Partially aggregated model Mfog
1: Apply FedAvg on received shares: Mfog ← n1 Pn i=1 Si
2: Send Mfog to leader server for global aggregation
2.5 Leader Server Aggregation
The leader server, randomly selected from the pool of fog nodes, is responsible
for performing the global aggregation. Its primary role is to collect the partial
models from fog nodes, verify their authenticity, and compute the updated global
model.
2.5.1 Input Retrieval
The leader server retrieves all partial models Mfogj from the fog nodes according to its assigned index IndexLeader:
Mfog = {Mfog1, Mfog2, . . . , Mfogn}
2.5.2 Verification of Authenticity
Each received model is verified using digital signatures to ensure authenticity
and integrity:
V erify(Signfogj(Mfogj)) = T rue ∀j ∈ {1, . . . , n}
162.5.3 Global Aggregation
The leader server performs the global aggregation strictly as a summation of all
valid fog node contributions:
Mglobal = Pn j=1 Mfogj
This produces the unified global model, which represents the collective knowledge of all participants.
2.5.4 Global Model Redistribution
After the leader server computes the global aggregation:
Mglobal = Pn j=1 Mfogj
the leader server without cp abe distributes the resulting global model to all registered medical facilities.
The broadcast is defined as:
Broadcast = {Indexuser1||Mglobal, Indexuser2||Mglobal, . . . , Indexusern||Mglobal}
Each facility receives the aggregated global model Mglobal according to its index. Once received, each facility initializes local training. The model is trained
for a specified number of epochs E using the facility’s local dataset Di. The
local update rule is:
Mlocali = Mglobal − η∇Fi(Mglobal)
where:
• η is the learning rate,
• Fi(x) is the local loss function for facility i,
• ∇ is the gradient operator.
After training, each user divides the updated model into secret shares according to the number of fog nodes n, then sends them for committee validation
and subsequent partial aggregation. This broadcast–train–share cycle repeats
until the global model Mglobal converges to its final state. The leader server’s
retrieval of partial models, verification, global aggregation, and redistribution
of the global model are illustrated in Algorithm 8.


